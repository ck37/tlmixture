#' This function will be called from tlmixture() on each CV-TMLE split.
#'
#' @param splits tbd
#' @param outcome name of the outcome variable
#' @param exposures tbd
#' @param family tbd
#' @param quantiles_mixtures tbd
#' @param quantiles_exposures tbd
#' @param estimator_outcome tbd
#' @param estimator_propensity tbd
#' @param mixture_fn tbd
#' @param cluster_exposures tbd
#' @param folds_sl tbd
#' @param verbose tbd
#'
#' @importFrom SuperLearner SuperLearner SuperLearner.CV.control
#' @importFrom magrittr %>%
#' @importFrom dplyr ntile
#' @importFrom stats quantile predict
analyze_folds =
  function(splits, outcome, exposures,
           family,
           quantiles_mixtures,
           quantiles_exposures,
           estimator_outcome,
           estimator_propensity,
           mixture_fn,
           cluster_exposures,
           folds_sl = 2L,
           verbose = FALSE) {

    if (verbose) {
      cat("Analyzing a training/test split.\n")
    }

    # Training data split.
    data_train = rsample::analysis(splits)

    # Test / validation split.
    data_test = rsample::assessment(splits)

    # Define groups of exposures (skip this step by default)
    if (cluster_exposures) {
      stop("Automatic exposure clustering is not yet implemented.")
      # TBD.
      exposure_groups = NA
    } else if (is.list(exposures)) {
      # Exposures is already a list with each element being a group.
      exposure_groups = exposures
    } else {

      # Single group with all of the exposures.
      exposure_groups = list(exposures)
      # Add a name that will go into the group table.
      names(exposure_groups) = "all"
    }

    # A single vector with all exposure names.
    # (Will be the same as "exposures" if there is a single group, but if there
    # are multiple groups this vector version will be helpful.)
    all_exposures = unlist(exposure_groups)

    if (verbose) {
      cat("Exposure groups to analyze:", length(exposure_groups), "\n")
    }

    weights = list()

    # Quantile cutpoints for the mixture.
    cutpoints = list()
    test_results = list()

    # Loop over exposure groups.
    for (group_i in seq_along(exposure_groups)) {

      exposure_names = exposure_groups[[group_i]]

      # Convert each exposure in this group to quantiles.
      # TODO: extract the quantile probabilities so that they can be applied
      # to the test set.
      # NOTE: we are currently not using these quantiles.
      exp_quantiles = data_train[, exposure_names] %>%
        purrr::map_df(dplyr::ntile, quantiles_exposures)

      # Create exposure weights, hopefully resulting in a convex combination or
      # something similar.
      #result = create_exposure_weights(data_train,
      result = mixture_fn(data_train,
                          outcome,
                          exposures = exposure_names,
                          # Pass in all exposure groups in case they want to use for adjustment.
                          exposure_groups = exposure_groups,
                          quantiles = exp_quantiles,
                          verbose = verbose)

      # Extract any weights that were generated by the mixture estimator.
      weights[[group_i]] = result$weights


      # Create mixture on the training data.
      # TODO: support predict() in the pls version.
      mixture_train = predict(result, data_train)

      # original version.
      #mixture_train = as.vector(as.matrix(data_train[, exposure_names]) %*%
      #                            matrix(result$weights, ncol = 1))

      # Create mixture on the test data.
      mixture_test = predict(result, data_test)
      #mixture_test = as.vector(as.matrix(data_test[, exposure_names]) %*%
      #                           matrix(result$weights, ncol = 1))

      # Calculate quantiles to discretize the continuous mixture.
      quantiles = quantile(mixture_train,
                           probs = seq(0, 1, by = 1 / quantiles_mixtures))
      cutpoints[[group_i]] = quantiles

      # Discretize into quantiles (quantiles_mixtures)
      # If we don't set include.lowest = TRUE then the lowest obs will have an NA.
      # TODO: can generate error - quantiles are not unique.
      # We use .bincode() to avoid the "quantiles are not unique" possible error.
      # See https://stackoverflow.com/questions/16184947/cut-error-breaks-are-not-unique
      # mixture_bins = cut(mixture_train, breaks = quantiles, include.lowest = TRUE)
      mixture_bins = .bincode(mixture_train, breaks = quantiles, include.lowest = TRUE)
      #mixture_bins_test = cut(mixture_test, breaks = quantiles, include.lowest = TRUE)
      mixture_bins_test = .bincode(mixture_test, breaks = quantiles, include.lowest = TRUE)

      # For the outcome regression exclude the original exposures in this group
      # plus the outcome variable, and add in the mixture bins.
      # TODO: determine if we do want to include the other exposure groups.
      vars = setdiff(names(data_train), c(outcome, exposure_names))
      #vars = setdiff(names(data_train), exposure_names)
      df_outcome_reg = cbind(data_train[, vars],
                             # Mixture_bins is a factor but we just need the integer codes.
                             # TODO: perhaps this should be one-hot encoded instead?
                             mixture_bins = as.integer(mixture_bins))

      # Estimate pooled outcome regression that includes all of the quantiles.
      # E[ Y | mixture bins, adjustment variables]
      # TODO: support arbitrary estimators, like sl3, mlr, caret, etc.
      reg_outcome =
        SuperLearner(Y = data_train[[outcome]],
                     X = df_outcome_reg,
                     family = family,
                     cvControl = SuperLearner.CV.control(V = folds_sl,
                                                         # Stratify if we have a binary outcome.
                                                         stratifyCV = family == "binomial"),
                     SL.library = estimator_outcome)

      if (verbose) {
        cat("Outcome regression result:\n")
        print(reg_outcome)
      }

      # We can save the propensity estimators for each quantile.
      # Note though, that we are directly applying to test data so saving
      # seems pretty optional. Yet may be useful for later analysis.
      regs_propensity = list()

      test_result_df = NULL

      # Loop over bins.
      for (bin_i in seq(quantiles_mixtures)) {
        # (Could estimate outcome regression per mixture bin, but using pooled currently.)

        # This is our A
        is_current_bin = as.integer(as.integer(mixture_bins) == bin_i)

        # Estimate propensity score regression per mixture_bin.
        reg_propensity =
          # Suppress warnings like "In lognet(x, is.sparse, ix, jx, y, weights, offset, alpha,  ... :
          # one multinomial or binomial class has fewer than 8  observations; dangerous ground"
          # TODO: only suppress specific warnings, like Oleg has in stremr.
          suppressWarnings(
          # We convert mixture_bins to an integer because it's a factor.
          SuperLearner(Y = is_current_bin,
                       X = subset(df_outcome_reg, select = -c(mixture_bins)),
                       family = "binomial",
                       cvControl = SuperLearner.CV.control(V = folds_sl,
                                                           stratifyCV = TRUE),
                       SL.library = estimator_propensity)
          )

        if (verbose) {
          cat("Propensity regression result", paste0("(", bin_i, "):\n"))
          print(reg_propensity)
        }

        # Save fits to apply to test data.
        regs_propensity[[bin_i]] = reg_propensity


        ###############
        # Also apply directly to test data here.

        # Dataframe to hold our counterfactuals.
        df_outcome = data_test[, setdiff(names(data_test), c(outcome, exposure_names))]

        # Set all obs to have this mixture bin level.
        df_outcome$mixture_bins = bin_i

        # Predict Q(1, W) - all observations have this mixture level.
        if (class(reg_outcome) == "SuperLearner") {
          q_pred = predict(reg_outcome, df_outcome, onlySL = TRUE)$pred
        } else {
          q_pred = predict(reg_outcome, df_outcome)
        }

        df_propensity = subset(df_outcome, select = -c(mixture_bins))

        # Predict g - propensity to have this mixture level.
        if (class(reg_propensity) == "SuperLearner") {
          # TODO: is type = "response" needed for SuperLearner? Need to check.
          g_pred = predict(reg_propensity, df_propensity, onlySL = TRUE,
                           type = "response")$pred
        } else {
          g_pred = predict(reg_propensity, df_propensity, type = "response")
        }

        # TODO: make g_min a function argument.
        g_min = 0.00001

        # Trunctate g_hat
        g_pred = bound(g_pred, c(g_min, 1 - g_min))


        # Create clever covariate
        h1w = 1 / g_pred

        # is_current_bin = A (treatment indicator).
        test_treatment_indicator = as.integer(as.integer(mixture_bins_test) == bin_i)

        # Set NAs to 0 for now.
        # TODO: figure out why some are NAs - just NA in the data? Or due to quantiles.
        # TODO: use actual adjustment for missingness, or another solution.
        test_treatment_indicator[is.na(test_treatment_indicator)] = 0L

        #browser()

        haw = test_treatment_indicator * h1w

        # Confirm we have no NAs in our haw vector.
        stopifnot(sum(is.na(haw)) == 0L)

        # NOTE: we don't calculate IC here because we need to do CV-TMLE fluctuation
        # using all folds' results (later).

        # Create dataframe of results for this mixture quantile.
        new_result = data.frame(quantile = bin_i,
                                # TODO: calculate and return Y_star
                                y = data_test[[outcome]],
                                # This is our A for this quantile.
                                in_quantile = test_treatment_indicator,
                                q_pred, g_pred, h1w, haw)

        # Append to our tracking dataframe.
        test_result_df = rbind(test_result_df, new_result)

      }

      # Save mixture prediction on stacked test data.
      test_result_df[[paste0("mixture_", group_i)]] = mixture_test

      # Save the stacked set of mixture quantile results for this exposure group.
      test_results[[group_i]] = test_result_df
    }

    # Compile results.
    results =
      list(weights = weights,
           # Contains the exposure groups that we created on the training data.
           # (Not yet implemented)
           exposure_groups = exposure_groups,
           test_results = test_results,
           cutpoints = cutpoints)

    return(results)

}
