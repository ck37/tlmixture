---
title: "NIEHS Mixtures workshop 2015"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{NIEHS Mixtures Workshop 2015}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(here::here("vignettes"))

# Enable to generate high-res plots for the paper
#knitr::opts_chunk$set(dpi = 300, fig.width = 4, fig.height = 4)

library(magrittr)
```

See https://www.niehs.nih.gov/news/events/pastmtg/2015/statistical/index.cfm

## Simulated Dataset 1

### Import data

```{r data1_import}
data = rio::import("../inst/extdata/niehs-2015-dataset1.xls")
str(data)

task = list(
  id = "obs",
  exposures = paste0("X", 1:7),
  outcome = "Y")

task$covariates = setdiff(names(data), c(task$id, task$exposures, task$outcome))
task
```

### Exploratory data analysis

TODO: determine if we need to log-transform the data.

```{r data1_eda}
library(ggplot2)

for (exposure in task$exposures) {
  print(qplot(data[[exposure]]) + ggtitle(paste("Exposure:", exposure)) + theme_minimal())
}


# Log-transform the data.
for (exposure in task$exposures) {
  data[[exposure]] = log(data[[exposure]])
}

summary(data)

for (exposure in task$exposures) {
  print(qplot(data[[exposure]]) + ggtitle(paste("Exposure:", exposure)) + theme_minimal())
}

# Also log-transform Y?
# No, doesn't seem log-normally distributed.
qplot(data[[task$outcome]])
qplot(log(data[[task$outcome]]))



```

### Estimation

```{r data1_model}

library(tlmixture)
#folds_cvtmle = 2L
folds_cvtmle = 5L
estimators = c("SL.mean", "SL.glmnet", "SL.ranger")
cluster_exposures = FALSE
verbose = TRUE
quantiles_exposures = 4L
quantiles_mixtures = 3L

names(data)
class(data)

#(exposures = paste0("X", 1:3))

df = data[, !names(data) %in% task$id]
str(df)

# Normalize the exposures.
for (exposure in task$exposures) {
  df[[exposure]] = (df[[exposure]] - mean(df[[exposure]])) / sd(df[[exposure]])
}

# Review exposure distributions.
summary(df[, task$exposures])


# Compare to OLS.
reg = lm(as.formula(paste(task$outcome, "~ .")), data = df)
summary(reg)

# Create a noise z2 - temporary.
# TODO: fix tlmixture to work with 1 or 0 adjustment variables.
# This may be a bug in SuperLearner can comes up when doing propensity score estimation as part of CV-TMLE.
df$z2 = rnorm(nrow(df))
#df$z2 = NULL

task$exposures

library(tmle)

get_cores = function() getOption("sl.cores", RhpcBLASctl::get_num_cores())

dbarts2_50 = function(...) {
  tmle::tmle.SL.dbarts2(..., ntree = 50, nthread = get_cores()) }

ranger_fast = function(...) SL.ranger(..., num.trees = 150, num.threads = get_cores())

#mix_lib = c("SL.mean", "SL.lm")#, "ranger_fast", "dbarts2_50") 
#mix_lib = c("SL.mean", "SL.lm", "SL.glmnet", "ranger_fast", "SL.rpart")#, "dbarts2_50") 
#mix_lib = c("SL.mean", "lm2")
#mix_lib = c("SL.mean", "lm2", "ranger_fast")
mix_lib = c("lm2", "ranger_fast")
mix_sl_1 = function(...) mixture_backfit_sl(..., estimator_mixture = mix_lib) 


lm2 = function(...) {
  # Hide all the damn "prediction from rank-deficient fit may be misleading" warnings.
  suppressWarnings(SL.lm(...))
}

library(sl3)

lrnr_glm <- make_learner(Lrnr_glm)
lrnr_glm_fast <- make_learner(Lrnr_glm_fast)
lrnr_mean <- make_learner(Lrnr_mean)
# Can't use ranger - doesn't support offsets (presumably).
# lrnr_ranger100 <- make_learner(Lrnr_ranger, num.trees = 100)
# TODO: add offset support to Lrnr_glmnet.
lrnr_glmnet <- make_learner(Lrnr_glmnet)
lrnr_xgb <- make_learner(Lrnr_xgboost, nrounds = 100, nthread = get_cores(), eta = 0.1)
# stack <- make_learner(Stack, lrnr_glm, lrnr_mean)
stack <- make_learner(Stack,
                     # lrnr_glm,
                      lrnr_mean, lrnr_glm_fast, lrnr_xgb)#, lrnr_glmnet)
sl <- Lrnr_sl$new(learners = stack,
                  metalearner = make_learner(Lrnr_nnls))

estimator_sl3 = function(...) {
  tlmixture::mixture_backfit_sl3(...,
                                 estimator_mixture = sl$clone(),
                                 estimator_confounders = sl$clone())
}
```

```{r run_tlmixture}

result = tlmixture(df, outcome = task$outcome,
                   exposures = task$exposures,
                   quantiles_exposures = quantiles_exposures,
                   #quantiles_mixtures = quantiles_mixtures,
                   quantiles_mixtures = 3,
                   #quantiles_mixtures = 5,
                   #estimator_outcome = estimators,
                   #estimator_outcome = c("SL.mean", "SL.lm"),
                   estimator_outcome = c("SL.mean", "lm2", "ranger_fast"),
                   cluster_exposures = cluster_exposures,
                   #mixture_fn = tlmixture::mixture_backfit_glm,
                   #mixture_fn = mixture_backfit_glm,
                   #mixture_fn = tlmixture::mixture_backfit_lm,
                   mixture_fn = mixture_backfit_sl3,
                   #mixture_fn = estimator_sl3,
                   #folds_cvtmle = folds_cvtmle,
                   #folds_cvtmle = 3,
                   folds_cvtmle = 5,
                   #folds_cvtmle = 10,
                   #folds_cvtmle = 20,
                   verbose = TRUE)

result$combined$results
result$combined$groups_df
qplot(result$groups$mixture_df$all)
```

### Test backfit lm

```{r backfit_test, eval = FALSE}
df2 = df
df2$z2 = NULL
#res = mixture_backfit_lm(df2,
res = mixture_backfit_sl(df2,
                         task$outcome, task$exposures,
                         max_iterations = 5L,
                         verbose = TRUE)

res
res$coefs_mixture[50L, ]
summary(res$reg_mixture)
summary(res$reg_adjust)

# Check prediction.
preds = predict(res, data[, res$exposures])
dim(preds)
qplot(preds)
preds = predict(res$reg_mixture, data[, res$exposures], onlySL = TRUE)
str(preds)
result$groups$groups_df
```


### Review results

```{r data1_results}
summary(result$outcome_rescaled)
data[[result$outcome]] = result$outcome_rescaled

# Analyze mixture distribution.
mix_result = analyze_mixture(data, result,
                             name = "Dataset 1",
                             reg_vars = task$covariates,
                             vars_desc = task$covariates)

# TODO: consider integrating plot_analysis() into analyze_mixture()
plot_analysis(mix_result)

weight_df = do.call(rbind, sapply(result$folds, `[[`, "weights"))
colMeans(weight_df)
```

```{r data1_display, results="asis"}
display_mixture(mix_result)
# Run again, this time as latex.
options(knitr.table.format = "latex")
kab_tab = display_mixture(mix_result)
cat(kab_tab, file = "data1-summary-table.tex")
# Restore previous table format setting.
# We unfortunately can't just assign it to NULL :/ Have to pick a specific value.
options(knitr.table.format = "html")
      
```

## Simulated Dataset 2

### Import data

```{r data2_import}
data2 = rio::import("../inst/extdata/niehs-2015-dataset2.xls")
str(data2)

names(data2) = tolower(names(data2))

task2 = list(
  id = "obs",
  exposures = paste0("x", 1:14),
  outcome = "y")

task2$covariates = setdiff(names(data2), c(task2$id, task2$exposures, task2$outcome))
task2
```

### Exploratory data analysis

TODO: determine if we need to log-transform the data.

```{r data2_eda}
library(ggplot2)

for (exposure in task2$exposures) {
  print(qplot(data2[[exposure]]) + ggtitle(paste("Exposure:", exposure)) + theme_minimal())
}


# Skip log-transforming the data.
if (FALSE) {
for (exposure in task2$exposures) {
  data2[[exposure]] = log(data[[exposure]])
}

print(summary(data2))

for (exposure in task2$exposures) {
  print(qplot(data2[[exposure]]) + ggtitle(paste("Exposure:", exposure)) + theme_minimal())
}

}

```

### Estimation

```{r data2_model}

library(tlmixture)
library(tmle)
#folds_cvtmle = 2L
folds_cvtmle = 5L
#estimators = c("SL.mean", "SL.glmnet", "SL.ranger", "tmle.SL.dbarts2")
#estimators = c("SL.mean", "SL.glmnet", "SL.ranger")
estimators = c("SL.mean", "lm2", "ranger_fast")
cluster_exposures = FALSE
verbose = TRUE
quantiles_exposures = 4L
quantiles_mixtures = 3L

names(data2)
(exposures = task2$exposures)
class(data2)

task2$exposures

# Simpler version.
#(exposures = paste0("x", 1:3))

df2 = data2[, !names(data2) %in% task2$id]
str(df2)

# Create a noise z2 - temporary.
# TODO: fix tlmixture to work with 1 or 0 adjustment variables.
#df$z2 = rnorm(nrow(df))

result2 = tlmixture(df2, outcome = task2$outcome,
                   exposures = exposures,
                   quantiles_exposures = quantiles_exposures,
                   #quantiles_mixtures = quantiles_mixtures,
                   quantiles_mixtures = 4,
                   #quantiles_mixtures = 5,
                   estimator_outcome = estimators,
                   cluster_exposures = cluster_exposures,
                   #mixture_fn = mixture_backfit_sl3,
                   mixture_fn = estimator_sl3,
                   #mixture_fn = sl_mix_2,
                   #folds_cvtmle = folds_cvtmle,
                   #folds_cvtmle = 3,
                   #folds_cvtmle = 4,
                   folds_cvtmle = 5,
                   # folds_cvtmle = 8,
                   #folds_cvtmle = 10,
                   #folds_cvtmle = 20,
                   verbose = TRUE)

# TODO: compile mixture predictions from test folds so that we can analyze post-hoc.
# result$folds[[1]]$test_results
```

### Review results

```{r data2_results}
summary(result2$outcome_rescaled)
data2[[result2$outcome]] = result2$outcome_rescaled
# Analyze mixture distribution.
# TODO: fix "unknown column" error due to rescaling of outcome variable.
mix_result2 = analyze_mixture(data2, result2,
                             name = "Dataset 2",
                             reg_vars = task2$covariates,
                             vars_desc = task2$covariates)

# TODO: get plot_analysis() working.
plot_analysis(mix_result2)
```
```{r results="asis"}
# Run once and display as html.
display_mixture(mix_result2)
# Run again, this time as latex.
options(knitr.table.format = "latex")
kab_tab = display_mixture(mix_result2)
cat(kab_tab, file = "data2-summary-table.tex")
# Restore previous table format setting.
options(knitr.table.format = "html")
#getOption("knitr.table.format")
```
